{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Split date feature\n",
    "- Mean/median imputation for numeric features\n",
    "- Random value imputation for most of categorical features\n",
    "- Label encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../../../../datasets/parte1/weatherAUS.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split Date Feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of using the full date, extracting just the month is much more valuable due to rain seasonality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Date'] = pd.to_datetime(df['Date'], format=\"%Y-%m-%d\", utc=True)\n",
    "df['Month'] = df['Date'].dt.month\n",
    "df.drop(['Date'], inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Handle Missing Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Mean/Median imputation in numeric features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Median imputation for features with skewed distribution due to its significant percentage of outliers\n",
    "- Mean imputation for the reamining ones as the mean is sensitive to extreme values, being recommended for data with less outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['WindSpeed9am'].fillna(df['WindSpeed9am'].median() , inplace=True)\n",
    "df['WindSpeed3pm'].fillna(df['WindSpeed3pm'].median() , inplace=True)\n",
    "df['Rainfall'].fillna(df['Rainfall'].median() , inplace=True)\n",
    "df['Evaporation'].fillna(df['Evaporation'].median() , inplace=True)\n",
    "df['WindGustSpeed'].fillna(df['WindGustSpeed'].mean() , inplace=True)\n",
    "df['MinTemp'].fillna(df['MinTemp'].mean(), inplace=True)\n",
    "df['MaxTemp'].fillna(df['MaxTemp'].mean() , inplace=True)\n",
    "df['Sunshine'].fillna(df['Sunshine'].mean() , inplace=True)\n",
    "df['Humidity9am'].fillna(df['Humidity9am'].mean() , inplace=True)\n",
    "df['Humidity3pm'].fillna(df['Humidity3pm'].mean() , inplace=True)\n",
    "df['Pressure9am'].fillna(df['Pressure9am'].mean() , inplace=True)\n",
    "df['Pressure3pm'].fillna(df['Pressure3pm'].mean() , inplace=True)\n",
    "df['Temp9am'].fillna(df['Temp9am'].mean() , inplace=True)\n",
    "df['Temp3pm'].fillna(df['Temp3pm'].mean() , inplace=True)\n",
    "df['Cloud9am'].fillna(df['Cloud9am'].mean() , inplace=True)\n",
    "df['Cloud3pm'].fillna(df['Cloud3pm'].mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Random value for direction features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Replace missing values with random values drawn from the distribution of observed values in the variable\n",
    "- Provides a more realistic approach compared to simple imputation methods because ensures that the overall distribution of the categorical variable is preserved, maintaining its statistical properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FAZEMOS ISTO PORQUE AS FEATURES CATEGORIAS ESTAO BEM DISTRIBUIDAS E PORTANTO A MODA NAO REPRESENTA UMA GRANDE PARTE DOS DADOS\n",
    "categorical_features = [col for col in df.columns if df[col].dtype == object]\n",
    "categorical_features.remove('RainTomorrow')\n",
    "categorical_features.remove('RainToday')\n",
    "categorical_features.remove('Location')\n",
    "\n",
    "for col in categorical_features:\n",
    "    values = df['WindDir3pm'].value_counts().index.values\n",
    "    probs = df[col].value_counts(normalize=True).values\n",
    "    df[col].replace(np.nan, np.random.choice(a=values, p=probs), inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Drop other categorical columns missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DEPOIS TIRAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature in df.select_dtypes(include=['int', 'float']).columns:\n",
    "        Q1 = df[feature].quantile(0.25)\n",
    "        Q3 = df[feature].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "\n",
    "        lower_bound = Q1 - 1.5 * IQR\n",
    "        upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "        # Remove outliers for the current numeric feature\n",
    "        df = df[(df[feature] >= lower_bound) & (df[feature] <= upper_bound)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Label Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converts categorical data into numerical format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "\n",
    "df['Location'] = label_encoder.fit_transform(df['Location'])\n",
    "df['WindGustDir'] = label_encoder.fit_transform(df['WindGustDir'])\n",
    "df['WindDir9am'] = label_encoder.fit_transform(df['WindDir9am'])\n",
    "df['WindDir3pm'] = label_encoder.fit_transform(df['WindDir3pm'])\n",
    "df['RainToday'] = label_encoder.fit_transform(df['RainToday'])\n",
    "df['RainTomorrow'] = label_encoder.fit_transform(df['RainTomorrow'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Write Prepared Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('../../../../datasets/parte1/dataset_cleaned.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.13 ('daa1')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b591d187f37fd73410aa6677fb7622cf9fb1a6dcb0be9eb075fceec3f912c4c8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
